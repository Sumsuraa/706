{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8419996a",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db3ca2",
   "metadata": {},
   "source": [
    "Once you have trained the model, simple run the cell below and it will ask for input. Input the text and it will classifiy it either as negative, positive or neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aff0e3f-df91-48c4-967a-854a6b8ee179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the input text is: positive\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc1 = nn.Linear(embed_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, num_class)\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        x = F.relu(self.fc1(embedded))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_url(text):\n",
    "    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def clean_text(text):\n",
    "    delete_dict = {sp_character: '' for sp_character in string.punctuation}\n",
    "    delete_dict[' '] = ' '\n",
    "    table = str.maketrans(delete_dict)\n",
    "    text1 = text.translate(table)\n",
    "    text_arr = text1.split()\n",
    "    text2 = ' '.join([w for w in text_arr if not w.isdigit() and len(w) > 2])\n",
    "    return text2.lower()\n",
    "\n",
    "def load_vocab(vocab_path):\n",
    "    with open(vocab_path, \"rb\") as f:\n",
    "        vocab = pickle.load(f)\n",
    "    return vocab\n",
    "\n",
    "def load_model(model_path, vocab_size, embed_dim, num_class):\n",
    "    model = TextClassificationModel(vocab_size, embed_dim, num_class)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def classify_text(model, vocab, text_pipeline, input_text):\n",
    "    processed_text = torch.tensor(text_pipeline(input_text), dtype=torch.int64)\n",
    "    offsets = torch.tensor([0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(processed_text, offsets)\n",
    "        predicted_label = output.argmax(1).item()\n",
    "\n",
    "    sentiment_dict = {0: \"neutral\", 1: \"negative\", 2: \"positive\"}\n",
    "    return sentiment_dict.get(predicted_label, \"unknown\")\n",
    "\n",
    "model_path = \"model.pth\"\n",
    "vocab_path = \"vocab.pkl\"\n",
    "embed_dim = 128\n",
    "num_class = 3  \n",
    "\n",
    "vocab = load_vocab(vocab_path)\n",
    "text_pipeline = lambda x: vocab(get_tokenizer('basic_english')(clean_text(remove_url(remove_emoji(x)))))\n",
    "vocab_size = len(vocab)\n",
    "model = load_model(model_path, vocab_size, embed_dim, num_class)\n",
    "\n",
    "input_text = input(\"Enter text to classify: \")\n",
    "\n",
    "sentiment = classify_text(model, vocab, text_pipeline, input_text)\n",
    "print(f\"The sentiment of the input text is: {sentiment}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
